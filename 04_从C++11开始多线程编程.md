# 从C++11开始的多线程编程

## 时间

### C语言如何处理时间 : time.h

```c
long t0 = time(NULL);	// 获取从1970年1月1日到当前时经过的秒数
sleep(3);				// 让程序休眠3秒
long t1 = t0 + 3;     	// 当前时间的三秒后
usleep(3000000);       	// 让程序休眠3000000微秒，也就是3秒
```

C语言原始的API,没有**类型区分**,很容易弄错**时间单位**,混淆**时间点**和**时间段**

例如t0 * 3, 乘法对于时间点来说是无意义的,然而C语言把它们看成一样的long类型,容易犯错

### C++的处理方式

#### C++11引入了时间标准库: std::chrono

利用C++强类型的特点,明确区分**时间点**和**时间段**,明确区分不同的**时间单位**

* 时间点 

  例子 : 2022年2月22日22时22分22秒

  类型 : chrono::steady_clock, chrono::time_point 等

* 时间段

  例子 : 1分钟

  类型 : chrono::milliseconds, chrono::seconds, chrono::minutes 等

同时C++11也提供了方便的运算符重载,时间点+时间段=时间点,时间点-时间点=时间段

```c++
auto t0 = chrono_clock::now();										//获取当前时间点
auto t1 = t0 + chrono::seconds(30);									//获取当前时间点的三十秒后
auto dt = t1 - t0;													//获取两个时间点的差(时间段)
int64_t sec = chrono::duration_cast<chrono::seconds>(dt).count();	//时间差的秒数
```

此时sec为整数,如果想精确到小数位,可以使用

```cpp
using double_ms = std::chrono::duration<double,std::milli>;
double ms = std::chrono::duration_cast<double_ms>(dt).count();
```

可见上面的chrono::seconds就是std::chrono::duration<int, std::milli>的缩写

duration_cast 可以在任意的 duration 类型之间转换,duration<T, R> 表示用 T 类型表示,且时间单位是 R

R 省略不写就是秒，std::milli 就是毫秒，std::micro 就是微秒

seconds 是 duration<int64_t> 的类型别名, milliseconds 是 duration<int64_t, std::milli> 的类型别名

这里我们创建了 double_ms 作为 duration<double, std::milli> 的别名

#### 跨平台的sleep: std::this_thread::sleep_for

可以使用 std::this_thread::sleep_for 替代Unix类操作系统专有的usleep. 它可以让当前线程休眠一段时间,然后继续

且单位也可以自己指定,下面的例程中单位为毫秒,也可以换成microseconds表示微秒,seconds表示秒

```cpp
std::this_thread::sleep_for(std::chrono::milliseconds(400));
```

除了接受一个时间段的 sleep_for,还有接受一个时间点的 sleep_until,表示让当前线程休眠直到某个时间点

```cpp
auto t = std::chrono::steady_clock::now() + std::chrono::seconds(10);
std::this_thread::sleep_until(t);
```

## 线程

### 进程和线程

**进程**是一个应用程序被操作系统拉起来加载到内存之后从开始执行到执行结束的这样一个过程。简单来说，进程是程序（应用程序，可执行文件）的一次执行。比如双击打开一个桌面应用软件就是开启了一个进程

**线程**是进程中的一个实体，是被系统独立分配和调度的基本单位。也有说，线程是CPU可执行调度的最小单位。也就是说，进程本身并不能获取CPU时间，只有它的线程才可以

从属关系：进程 > 线程。一个进程可以拥有多个线程

每个线程共享同样的内存空间，开销比较小

每个进程拥有独立的内存空间，因此开销更大

对于高性能并行计算，更好的是多线程 

### 为什么需要多线程

**无阻塞多任务**

我们的程序常常需要同时处理多个任务

例如：后台在执行一个很耗时的任务，比如下载一个文件，同时还要和用户交互

这在 GUI 应用程序中很常见，比如浏览器在后台下载文件的同时，用户仍然可以用鼠标操作其 UI 界面

没有多线程的话,必须要等到当前任务完成之后才能响应

例如

```cpp
#include <iostream>
#include <thread>
#include <string>
void download(std::string file) {
    for (int i = 0; i < 10; i++) {
        std::cout << "Downloading " << file
                  << " (" << i * 10 << "%)..." << std::endl;
        std::this_thread::sleep_for(std::chrono::milliseconds(400));
    }
    std::cout << "Download complete: " << file << std::endl;
}
void interact() {
    std::string name;
    std::cin >> name;
    std::cout << "Hi, " << name << std::endl;
}
int main() {
    download("hello.zip");
    interact();
    return 0;
}
```

运行后就会发现,在download完成之前,在控制台中输入文字不能调用interact(),而要等到download完成之后

### 线代C++中的多线程 : std::thread

#### 简介

C++11开始,为多线程提供了语言级的支持.它用std::thread这个类表示进程

std::thread构造函数的参数可以是任意lambda表达式,当线程启动时,便会执行lambda中的内容

如

```cpp
#include <iostream>
#include <thread>
#include <string>
void download(std::string file) {
    for (int i = 0; i < 10; i++) {
        std::cout << "Downloading " << file
                  << " (" << i * 10 << "%)..." << std::endl;
        std::this_thread::sleep_for(std::chrono::milliseconds(400));
    }
    std::cout << "Download complete: " << file << std::endl;
}
void interact() {
    std::string name;
    std::cin >> name;
    std::cout << "Hi, " << name << std::endl;
}
int main() {
    std::thread t1([&] {
        download("hello.zip");
    });
    interact();
    return 0;
}
```

如果尝试编译这段代码,会在链接时发生错误(Linux),这是因为Linux没有真正的线程,它的实现是由pthread库基于进程模拟的,而Windows是真正存在线程的概念的,于是Windows的编译并不会出错

解决方案:
在CMakeLists.txt中设置链接Threads::Threads即可

```cmake
find_package(Threads REQUIRED)
target_link_libraries(test PUBLIC Threads::Threads)
```

#### 异步处理 : join()

输入完 字符串以后,他的确及时地和我交互了,但是**用户交互**所在的主线程退出后,**文件下载**所在的子线程,因为从属于这个主线程,也被迫退出了

因此,我们想要让主线程不要急着退出,等子线程也结束了再退出.可以用 std::thread 类的成员函数 join() 来等待该进程结束

```cpp
int main() {
    std::thread t1([&] {
        download("hello.zip");
    });
    interact();
    t1.join();
    return 0;
}
```

#### 出师未捷身先死 : detach()

对于

```cpp
void download(std::string file) {...}
void interact() {...}
void myfunc() {
    std::thread t1([&] {
        download("hello.zip");
    });
    // 退出函数体时，会销毁 t1 线程的句柄！
}
int main() {
    myfunc();
    interact();
    return 0;
}
```

作为一个 C++ 类，std::thread 同样遵循 RAII 思想和三五法则：因为管理着资源，他自定义了**解构函数**，删除了**拷贝构造/赋值**函数，但是提供了**移动构造/赋值函数**。

因此，当 t1 所在的函数退出时，就会调用 std::thread 的解构函数，这会销毁 t1 线程

所以，download 函数才会出师未捷身先死——还没开始执行他的线程就被销毁了

解决方案：调用成员函数 detach() 分离该线程——意味着线程的生命周期**不再由当前std::thread对象管理**,而是在线程退出以后自动销毁自己.不过这样还是会在进程退出时候自动退出。

```cpp
void myfunc() {
    std::thread t1([&] {
        download("hello.zip");
    });
    t1.detach();
    // t1 所代表的线程被分离了，不再随 t1 对象销毁
}
```

#### 全局线程池

detach()的问题在于进程退出时不会等到所有线程执行完毕,一旦输入内容调用interact(),download也随之结束

另一种解决方案 : 把 t1 对象**移动**到一个全局变量去.从而延长其生命周期到 myfunc 函数体外.这样就可以等下载完再退出了

```cpp
void download(std::string file) {...}
void interact() {...}
std::vector<std::thread> pool;

void myfunc() {
    std::thread t1([&] {
        download("hello.zip");
    });
    // 移交控制权到全局的 pool 列表，以延长 t1 的生命周期
    pool.push_back(std::move(t1));
}

int main() {
    myfunc();
    interact();
    for (auto &t: pool) t.join();  // 等待池里的线程全部执行完毕
    return 0;
}
```

但这样还是不方便,我必须修改我的main函数才行,我们可以自定义一个类 ThreadPool，并用他创建一个全局变量，其解构函数会在 main 退出后自动调用

```cpp
class ThreadPool {
    std::vector<std::thread> m_pool;

public:
    void push_back(std::thread thr) {
        m_pool.push_back(std::move(thr));
    }

    ~ThreadPool() {                      // main 函数退出后会自动调用
        for (auto &t: m_pool) t.join();  // 等待池里的线程全部执行完毕
    }
};

ThreadPool tpool;

void myfunc() {
    std::thread t1([&] {
        download("hello.zip");
    });
    // 移交控制权到全局的 pool 列表，以延长 t1 的生命周期
    tpool.push_back(std::move(t1));
}

int main() {
    myfunc();
    interact();
    return 0;
}
```

#### 美好的未来

C++20将会加入std::jthread类,它的结构函数里会自动调用join()函数,保证pool解构时会等待全部线程执行完毕

## 异步

### std::async

std::async 接受一个带返回值的 lambda，自身返回一个 std::future 对象。

lambda 的函数体将在**另一个线程**里执行。

接下来你可以在 main 里面做一些别的事情，download 会持续在后台悄悄运行。

最后调用 future 的 get() 方法，如果此时 download 还没完成，会**等待** download 完成，并获取 download 的返回值。

```cpp
#include <iostream>
#include <string>
#include <thread>
#include <future>

int download(std::string file) {
    ...
    return 404;
}

void interact() {...}

int main() {
    std::future<int> fret = std::async([&] {
        return download("hello.zip"); 
    });
    interact();
    int ret = fret.get();
    std::cout << "Download result: " << ret << std::endl;
    return 0;
}
```

### 显式的等待 : wait()

wait()是future类的成员函数

除了 get() 会等待线程执行完毕外，wait() 也可以等待他执行完，但是不会返回其值

```cpp
int main() {
    std::future<int> fret = std::async([&] {
        return download("hello.zip"); 
    });
    interact();
    std::cout << "Waiting for download complete..." << std::endl;
    fret.wait(); // 在线程执行完毕之前 下面的语句将不会执行 只要线程没有执行完,wait() 会无限等下去
    std::cout << "Wait returned!" << std::endl;
    int ret = fret.get();
    std::cout << "Download result: " << ret << std::endl;
    return 0;
}
```

 wait_for() 则可以指定一个最长等待时间，用 chrono 里的类表示单位。他会返回一个 std::future_status 表示等待是否成功。

如果超过这个时间线程还没有执行完毕，则放弃等待，返回 future_status::timeout

如果线程在指定的时间内执行完毕，则认为等待成功，返回 future_status::ready

同理还有 wait_until() 其参数是一个时间点

```cpp
int main() {
    std::future<int> fret = std::async([&] {
        return download("hello.zip"); 
    });
    interact();
    while (true) {
        std::cout << "Waiting for download complete..." << std::endl;
        auto stat = fret.wait_for(std::chrono::milliseconds(1000));
        if (stat == std::future_status::ready) {
            std::cout << "Future is ready!!" << std::endl;
            break;
        } else {
            std::cout << "Future not ready!!" << std::endl;
        }
    }
    int ret = fret.get();
    std::cout << "Download result: " << ret << std::endl;
    return 0;
}
```

### std::async的底层实现 : std::promise

如果不想让 std::async 帮你自动创建线程，想要手动创建线程，可以直接用 std::promise

然后在线程返回的时候，用 set_value() 设置返回值。在主线程里，用 get_future() 获取其 std::future 对象，进一步 get() 可以等待并获取线程返回值

```cpp
int main() {
    std::promise<int> pret;
    std::thread t1([&] {
        auto ret = download("hello.zip");
        pret.set_value(ret); 
    });
    std::future<int> fret = pret.get_future();

    interact();
    int ret = fret.get();
    std::cout << "Download result: " << ret << std::endl;

    t1.join();
    return 0;
}
```

*注 : 并不重要,std::async都包装好了,用它就行*

### 小贴士

1. future 为了三五法则，删除了拷贝构造/赋值函数。如果需要浅拷贝，实现共享同一个 future 对象，可以用 std::shared_future,与shared_ptr类似

2. 如果不需要返回值，std::async 里 lambda 的返回类型可以为 void， 这时 future 对象的类型为 *std::future<void>*。

## 互斥量

### 什么是互斥量 : 多线程打架案例

如果两个线程同时往一个vector里推数据,就会导致崩溃,这是因为vector不是多线程安全(MT-safe)的容器,多个线程同时访问同一个vector会出现**数据竞争**(data-race)现象

### std::mutex : 上锁

调用 std::mutex 的 lock() 时，会检测 mutex 是否已经**上锁**

如果没有**锁定**，则对 mutex 进行**上锁**

如果已经**锁定**，则陷入等待，直到 mutex 被另一个线程**解锁**后，才再次**上锁**

而调用 unlock() 则会进行解锁操作

这样，就可以保证 mtx.lock() 和 mtx.unlock() 之间的代码段，同一时间只有一个线程在执行，从而避免数据竞争

```cpp
#include <iostream>
#include <string>
#include <thread>
#include <vector>
#include <mutex>

int main() {
    std::vector<int> arr;
    std::mutex mtx;
    std::thread t1([&] {
        for (int i = 0; i < 1000; i++) {
            mtx.lock();
            arr.push_back(1);
            mtx.unlock();
        }
    });
    std::thread t2([&] {
        for (int i = 0; i < 1000; i++) {
            mtx.lock();
            arr.push_back(2);
            mtx.unlock();
        }
    });
    t1.join();
    t2.join();
    return 0;
}
```

### 符合RAII思想的上锁和解锁

根据 RAII 思想，可将锁的持有视为资源，上锁视为锁的获取，解锁视为锁的释放

std::lock_guard 就是这样一个工具类，他的构造函数里会调用 mtx.lock()，解构函数会调用 mtx.unlock()。从而退出函数作用域时能够自动解锁，避免程序员粗心不小心忘记解锁

```cpp
std::lock_guard grd(mtx);
```

### 更自由 : std::unique_lock (推荐)

std::lock_guard 严格在解构时 unlock()，但是有时候我们会希望提前 unlock()。这时可以用 std::unique_lock类，他额外存储了一个 flag 表示是否已经被释放。他会在解构检测这个 flag，如果没有释放，则调用 unlock()，否则不调用

然后可以直接调用 unique_lock 的 unlock() 函数来提前解锁，但是即使忘记解锁也没关系，退出作用域时候他还会自动检查一遍要不要解锁

```cpp
 std::unique_lock grd(mtx);
```

### 多个对象的mutex

```cpp
int main() {
    std::vector<int> arr1;
    std::mutex mtx1;

    std::vector<int> arr2;
    std::mutex mtx2;

    std::thread t1([&] {
        for (int i = 0; i < 1000; i++) {
            {
                std::lock_guard grd(mtx1);
                arr1.push_back(1);
            }

            {
                std::lock_guard grd(mtx2);
                arr2.push_back(1);
            }
        }
    });
    std::thread t2([&] {
        for (int i = 0; i < 1000; i++) {
            {
                std::lock_guard grd(mtx1);
                arr1.push_back(2);
            }

            {
                std::lock_guard grd(mtx2);
                arr2.push_back(2);
            }
        }
    });
    t1.join();
    t2.join();
    return 0;
}
```

注意这里用了一个 {} 包住 std::lock_guard，限制其变量的作用域，从而可以让他在 } 之前解构并调用 unlock()，也避免了和下面一个 lock_guard 变量名冲突

### try.lock()

我们说过 lock() 如果发现 mutex 已经上锁的话，会等待他直到他解锁

也可以用无阻塞的 try_lock()，他在上锁失败时不会陷入等待，而是直接返回 false；如果上锁成功，则会返回 true

比如这个例子

```cpp
std::mutex mtx1;

int main() {
    if (mtx1.try_lock())
        printf("succeed\n");
    else
        printf("failed\n");

    if (mtx1.try_lock())
        printf("succeed\n");
    else
        printf("failed\n");

    mtx1.unlock();
    return 0;
}
```

第一次上锁，因为还没有人上锁，所以成功了，返回 true

第二次上锁，由于自己已经上锁，所以失败了，返回 false

还有一个try_lock_for(),会在解锁失败后等待一段时间,同样由std::chrono指定,同理也存在try_lock_until()

### std::unique_lock的参数

这里的参数调用方式统一为std::unqiue_lock grd(mtx,参数);

1. std::defer_lock

指定了这个参数的话，std::unique_lock 不会在构造函数中调用 mtx.lock()，需要之后再手动调用 grd.lock() 才能上锁

2. std::try_to_lock(注意不是std::try_lock)

和无参数相比，他会调用 mtx1.try_lock() 而不是 mtx1.lock()。之后，可以用 grd.owns_lock() 判断是否上锁成功

```cpp
if (grd.owns_lock())
	...
```

3. atd::adopt_lock

   如果当前 mutex 已经上锁了，但是之后仍然希望用 RAII 思想在解构时候自动调用 unlock()，可以用 std::adopt_lock 作为 std::unique_lock 或 std::lock_guard 的第二个参数，这时他们会默认 mtx 已经上锁。

### **std::unique_lock 和 std::mutex 具有同样的接口**

其实 std::unique_lock 具有 mutex 的所有成员函数：lock(), unlock(), try_lock(), try_lock_for() 等。除了他会在解构时按需自动调用 unlock()

因为 std::lock_guard 无非是调用其构造参数名为 lock() 的成员函数，所以 std::unique_lock 也可以作为 std::lock_guard 的构造参数

这种只要具有某些指定名字的成员函数，就判断一个类是否满足某些功能的思想，在 Python 称为鸭子类型，而 C++ 称为 concept（概念）。比起虚函数和动态多态的接口抽象，concept 使实现和接口更加解耦合且没有性能损失

## 死锁

### 简介

•由于同时执行的两个线程，他们中发生的指令不一定是同步的，因此有可能出现这种情况：

```cpp
int main() {
    std::mutex mtx1;
    std::mutex mtx2;

    std::thread t1([&] {
        for (int i = 0; i < 1000; i++) {
            mtx1.lock();
            mtx2.lock();
            mtx2.unlock();
            mtx1.unlock();
        }
    });
    std::thread t2([&] {
        for (int i = 0; i < 1000; i++) {
            mtx2.lock();
            mtx1.lock();
            mtx1.unlock();
            mtx2.unlock();
        }
    });
    t1.join();
    t2.join();
    return 0;
}
```

t1 执行 mtx1.lock()。

t2 执行 mtx2.lock()。

t1 执行 mtx2.lock()：失败，陷入等待

t2 执行 mtx1.lock()：失败，陷入等待

双方都在等着对方释放锁，但是因为等待而无法释放锁，从而要无限制等下去。

这种现象称为**死锁**（dead-lock）

#### 解决方案1 : 永远不要同时持有两个锁

最为简单的方法，就是**一个线程永远不要同时持有两个锁**，分别上锁，这样也可以避免死锁

因此这里双方都在 mtx1.unlock() 之后才 mtx2.lock()，从而也不会出现一方等着对方的同时持有了对方等着的锁的情况

```cpp
int main() {
    std::mutex mtx1;
    std::mutex mtx2;

    std::thread t1([&] {
        for (int i = 0; i < 1000; i++) {
            mtx1.lock();
            mtx1.unlock();
            mtx2.lock();
            mtx2.unlock();
        }
    });
    std::thread t2([&] {
        for (int i = 0; i < 1000; i++) {
            mtx2.lock();
            mtx2.unlock();
            mtx1.lock();
            mtx1.unlock();
        }
    });
    t1.join();
    t2.join();
    return 0;
}
```

#### 解决方案2 : 保证双方上锁顺序一致

```cpp
int main() {
    std::mutex mtx1;
    std::mutex mtx2;

    std::thread t1([&] {
        for (int i = 0; i < 1000; i++) {
            mtx1.lock();
            mtx2.lock();
            mtx2.unlock();
            mtx1.unlock();
        }
    });
    std::thread t2([&] {
        for (int i = 0; i < 1000; i++) {
            mtx1.lock();
            mtx2.lock();
            mtx2.unlock();
            mtx1.unlock();
        }
    });
    t1.join();
    t2.join();
    return 0;
}
```

#### 解决方案3 : 用std::lock同时给多个对象上锁

如果没办法保证上锁顺序一致，可以用标准库的 std::lock(mtx1, mtx2, ...) 函数，一次性对多个 mutex 上锁。

他接受任意多个 mutex 作为参数，并且**保证在无论任意线程中调用的顺序是否相同，都不会产生死锁问题**

```cpp
int main() {
    std::mutex mtx1;
    std::mutex mtx2;

    std::thread t1([&] {
        for (int i = 0; i < 1000; i++) {
            std::lock(mtx1, mtx2);
            mtx1.unlock();
            mtx2.unlock();
        }
    });
    std::thread t2([&] {
        for (int i = 0; i < 1000; i++) {
            std::lock(mtx2, mtx1);
            mtx2.unlock();
            mtx1.unlock();
        }
    });
    t1.join();
    t2.join();
    return 0;
}
```

#### std::lock的RAII版本: std::scoped_lock

和 std::lock_guard 相对应，std::lock 也有 RAII 的版本 std::scoped_lock.只不过他可以同时对多个 mutex 上锁

```cpp
std::thread t1([&] {
        for (int i = 0; i < 1000; i++) {
            std::scoped_lock grd(mtx1, mtx2);
            // do something
        }
    });
    std::thread t2([&] {
        for (int i = 0; i < 1000; i++) {
            std::scoped_lock grd(mtx2, mtx1);
            // do something
        }
    });
```

### 另一种死锁

除了两个线程同时持有两个锁会造成死锁外，即使只有一个线程一个锁，如果 lock() 以后又调用 lock()，也会造成死锁

比如以下的 func 函数，上了锁之后，又调用了 other 函数，他也需要上锁。而 other 看到 mtx1 已经上锁，还以为是别的线程上的锁，于是陷入等待。殊不知是调用他的 func 上的锁，other 陷入等待后 func 里的 unlock() 永远得不到调用

```cpp
std::mutex mtx1;

void other() {
    mtx1.lock();
    // do something
    mtx1.unlock();
}

void func() {
    mtx1.lock();
    other();
    mtx1.unlock();
}

int main() {
    func();
    return 0;
}
```

#### 解决方案1: other里不要再上锁(推荐)

遇到这种情况最好是把 other 里的 lock() 去掉，并在其文档中说明：“other 不是线程安全的，调用本函数之前需要保证某 mutex 已经上锁"

#### 解决方案2 : 改用std::recursive_mutex

如果实在不能改的话，可以用 std::recursive_mutex。他会自动判断是不是同一个线程 lock() 了多次同一个锁，如果是则让计数器加1，之后 unlock() 会让计数器减1，减到0时才真正解锁。但是相比普通的 std::mutex 有一定性能损失

## 数据结构

 ### 线程安全的vector

```cpp
class MTVector {
    std::vector<int> m_arr;
    std::mutex m_mtx;

public:
    void push_back(int val) {
        m_mtx.lock();
        m_arr.push_back(val);
        m_mtx.unlock();
    }

    size_t size() const {
        m_mtx.lock();
        size_t ret = m_arr.size();
        m_mtx.unlock();
        return ret;
    }//出错! 因为size()是const的,但是mutex.lock()不是const的
};
```

我们要为了支持 mutex 而放弃声明 size() 为 const 吗？不必，size() 在**逻辑**上仍是 const 的。因此，为了让 this 为 const 时仅仅给 m_mtx 开后门，可以用 mutable 关键字修饰他，从而所有成员里只有他不是 const 的

```cpp
mutable std::mutex m_mtx;
```

### 读写锁

mutex 就像厕所，同一时刻只有一个人能上。但是如果“上”有两种方式呢？

假设在平行世界，厕所不一定是用来**拉**的，还可能是用来**喝**的

喝厕所里的水时，可以**多个人**插着吸管一起喝。

而拉的时候，只能**一个人独占**厕所，不能多个人一起往里面拉。

喝水的人如果发现厕所里已经有人在拉，那他也不能去喝，否则会喝到“**脏数据**”。

结论：**读可以共享，写必须独占，且写和读不能共存**

针对这种更具体的情况，又发明了读写锁，他允许的状态有：

1. n个人读取，没有人写入。

2. 1个人写入，没有人读取。

3. 没有人读取，也没有人写入。

为此，标准库提供了 std::shared_mutex。

```cpp
class MTVector {
    std::vector<int> m_arr;
    mutable std::shared_mutex m_mtx;

public:
    void push_back(int val) {
        m_mtx.lock();
        m_arr.push_back(val);
        m_mtx.unlock();
    }

    size_t size() const {
        m_mtx.lock_shared();
        size_t ret = m_arr.size();
        m_mtx.unlock_shared();
        return ret;
    }
};
```

上锁时，要指定你的需求是**拉**还是**喝**，负责调度的读写锁会帮你判断要不要等待。

这里 push_back() 需要修改数据，因需求此为**拉**，使用 lock() 和 unlock() 的组合。

而 size() 则只要读取数据，不修改数据，因此可以和别人共享一起**喝**，使用 lock_shared() 和 unlock_shared() 的组合。

### std::shared_lock() : 符合RAII的lock_shared()

```cpp
class MTVector {
    std::vector<int> m_arr;
    mutable std::shared_mutex m_mtx;

public:
    void push_back(int val) {
        std::unique_lock grd(m_mtx);
        m_arr.push_back(val);
    }

    size_t size() const {
        std::shared_lock grd(m_mtx);
        return m_arr.size();
    }
};
```

正如 std::unique_lock 针对 lock()，也可以用 std::shared_lock 针对 lock_shared()。这样就可以在函数体退出时自动调用 unlock_shared()，更加安全了

### 访问者模式

## 条件变量

### 条件变量 : 等待被唤醒

```cpp
#include <iostream>
#include <thread>
#include <mutex>
#include <condition_variable>

int main() {
    std::condition_variable cv;
    std::mutex mtx;

    std::thread t1([&] {
        std::unique_lock lck(mtx);
        cv.wait(lck);

        std::cout << "t1 is awake" << std::endl;
    });

    std::this_thread::sleep_for(std::chrono::milliseconds(400));

    std::cout << "notifying..." << std::endl;
    cv.notify_one();  // will awake t1

    t1.join();

    return 0;
}
```

cv.wait(lck) 将会让当前线程陷入等待。

在其他线程中调用 cv.notify_one() 则会唤醒那个陷入等待的线程。

可以发现 std::condition_variable 必须和 std::unique_lock\<std::mutex> 一起用，稍后会解释原因。

### 条件变量 : 等待某一条件成真

还可以额外指定一个参数，变成 cv.wait(lck, expr) 的形式，其中 expr 是个 lambda 表达式，只有其返回值为 true 时才会真正唤醒，否则继续等待。

```cpp
int main() {
    std::condition_variable cv;
    std::mutex mtx;
    bool ready = false;

    std::thread t1([&] {
        std::unique_lock lck(mtx);
        cv.wait(lck, [&] { return ready; });

        std::cout << "t1 is awake" << std::endl;
    });

    std::cout << "notifying not ready" << std::endl;
    cv.notify_one();  // useless now, since ready = false

    ready = true;
    std::cout << "notifying ready" << std::endl;
    cv.notify_one();  // awakening t1, since ready = true

    t1.join();

    return 0;
}
```

### 条件变量：多个等待者

cv.notify_one() 只会唤醒其中一个等待中的线程，而 cv.notify_all() 会唤醒全部。

这就是为什么 wait() 需要一个 unique_lock 作为参数，因为要保证多个线程被唤醒时，只有一个能够被启动。如果不需要，在 wait() 返回后调用 lck.unlock() 即可。

顺便一提，wait() 的过程中会暂时 unlock() 这个锁。

## 原子操作

### 案例 : 多个线程修改同一个计数器

多个线程同时往一个 int 变量里累加，这样肯定会出错，因为 counter += i 在 CPU 看来会变成三个指令：

1. 读取 counter 变量到 rax 寄存器

2. rax 寄存器的值加上 1

3. 把 rax 写入到 counter 变量

即使编译器优化成 *add [counter], 1* 也没用，因为现代 CPU 为了高效，使用了大量奇技淫巧，比如他会把一条汇编指令拆分成**很多微指令** **(micro-ops)**，如果同时读取,同时写入,势必会导致操作被覆盖

### 解决方案1 : mutex

这样的确可以防止多个线程同时修改 counter 变量，从而不会冲突

问题：mutex 太过重量级，他会让线程被挂起，从而需要通过系统调用，进入**内核层**，调度到其他线程执行，有很大的开销

可我们只是想要修改一个小小的 int 变量而已，用昂贵的 mutex 严重影响了效率

### 解决方案2 : atomic (推荐)

因此可以用更轻量级的 atomic，对他的 += 等操作，会被编译器转换成专门的指令。

CPU 识别到该指令时，会锁住内存总线，放弃乱序执行等优化策略（将该指令视为一个同步点，强制同步掉之前所有的内存操作），从而向你保证该操作是**原子** **(atomic)** 的（取其不可分割之意），不会加法加到一半另一个线程插一脚进来。

对于程序员，只需把 int 改成 atomic\<int> 即可，也不必像 mutex 那样需要手动上锁解锁，因此用起来也更直观。

```cpp
std::atomic<int> counter = 0;
```

**注意:**必须是+=,++才可以,counter = counter + 1;是不行的

除了用方便的运算符重载之外，还可以直接调用相应的函数名，比如：

* fetch_add 对应于 +=

  另外fetch_add会返回旧值

  ```cpp
  int old = atm.fetch_add(val)
  ```

  除了会导致 atm 的值增加 val 外，还会返回 atm 增加前的值，存储到 old。

  这个特点使得他可以用于**并行地往一个列表里追加数据**：追加写入的索引就是 fetch_add 返回的旧值。

* store 对应于 =

* load 用于读取其中的 int 值

* compare_exchange_strong : 读取,比较是否相等,相等则写入

  atm.compare_exchange_strong(old, val) 会读取原子变量的值，比较他是否和 old 相等

  如果不相等，则把原子变量的值写入 old。

  如果相等，则把 val 写入原子变量。 

  返回一个 bool 值，表示是否相等。

  注意 old 这里传的其实是一个引用，因此 compare_exchange_strong 可修改他的值。
